---
kindle-sync:
  bookId: '47787'
  title: 'Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow'
  author: Aurélien Géron
  asin: B0BHCFNY9Q
  lastAnnotatedDate: '2025-12-25'
  bookImageUrl: 'https://m.media-amazon.com/images/I/81qHV3ACapL._SY160.jpg'
  highlightsCount: 29
---
# Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow
## Metadata
* Author: [Aurélien Géron](https://www.amazon.comundefined)
* ASIN: B0BHCFNY9Q
* Reference: https://www.amazon.com/dp/B0BHCFNY9Q
* [Kindle link](kindle://book?action=open&asin=B0BHCFNY9Q)

## Highlights
A deep neural network is a (very) simplified model of our cerebral cortex, composed of a stack of layers of artificial neurons. — location: [34](kindle://book?action=open&asin=B0BHCFNY9Q&location=34) ^ref-52293

---
The first ML application that really became mainstream, improving the lives of hundreds of millions of people, took over the world back in the 1990s: the spam filter. — location: [269](kindle://book?action=open&asin=B0BHCFNY9Q&location=269) ^ref-2378

---
Machine learning is the science (and art) of programming computers so they can learn from data. — location: [346](kindle://book?action=open&asin=B0BHCFNY9Q&location=346) ^ref-7839

---
A computer program is said to learn from experience — location: [351](kindle://book?action=open&asin=B0BHCFNY9Q&location=351) ^ref-65321

---
E with respect to some task T and some performance measure P, if its performance on T, as measured by P, improves with experience E. Tom Mitchell, — location: [351](kindle://book?action=open&asin=B0BHCFNY9Q&location=351) ^ref-63449

---
The examples that the system uses to learn are called the training set. Each training example is called a training instance (or sample). The part of a machine learning system that learns and makes predictions is called a model. Neural networks and random forests are examples of models. — location: [357](kindle://book?action=open&asin=B0BHCFNY9Q&location=357) ^ref-58313

---
for example, you can use the ratio of correctly classified emails. This particular performance measure is called accuracy, and it is often used in classification tasks. — location: [361](kindle://book?action=open&asin=B0BHCFNY9Q&location=361) ^ref-19776

---
For instance, once a spam filter has been trained on enough spam, it can easily be inspected to reveal the list of words and combinations of words that it believes are the best predictors of spam. — location: [395](kindle://book?action=open&asin=B0BHCFNY9Q&location=395) ^ref-8028

---
Digging into large amounts of data to discover hidden patterns is called data mining, and machine learning excels at it. — location: [398](kindle://book?action=open&asin=B0BHCFNY9Q&location=398) ^ref-27652

---
machine learning is great for: Problems for which existing solutions require a lot of fine-tuning or long lists of rules (a machine learning model can often simplify code and perform better than the traditional approach) Complex problems for which using a traditional approach yields no good solution (the best machine learning techniques can perhaps find a solution) Fluctuating environments (a machine learning system can easily be retrained on new data, always keeping it up to date) Getting insights about complex problems and large amounts of data — location: [401](kindle://book?action=open&asin=B0BHCFNY9Q&location=401) ^ref-7983

---
Examples of Applications — location: [409](kindle://book?action=open&asin=B0BHCFNY9Q&location=409) ^ref-33156

---
There are so many different types of machine learning systems that it is useful to classify them in broad categories, based on the following criteria: How they are supervised during training (supervised, unsupervised, semi-supervised, self-supervised, and others) Whether or not they can learn incrementally on the fly (online versus batch learning) Whether they work by simply comparing new data points to known data points, or instead by detecting patterns in the training data and building a predictive model, much like scientists do (instance-based versus model-based learning) — location: [465](kindle://book?action=open&asin=B0BHCFNY9Q&location=465) ^ref-59903

---
In supervised learning, the training set you feed to the algorithm includes the desired solutions, called labels (Figure — location: [479](kindle://book?action=open&asin=B0BHCFNY9Q&location=479) ^ref-7108

---
Note that some regression models can be used for classification as well, and vice versa. For example, logistic regression is commonly used for classification, as it can output a value that corresponds to the probability of belonging to a given class (e.g., 20% chance of being spam). — location: [490](kindle://book?action=open&asin=B0BHCFNY9Q&location=490) ^ref-58966

---
In unsupervised learning, as you might guess, the training data is unlabeled (Figure 1-7). The system tries to learn without a teacher. — location: [507](kindle://book?action=open&asin=B0BHCFNY9Q&location=507) ^ref-8967

---
At no point do you tell the algorithm which group a visitor belongs to: it finds those connections without your help. — location: [512](kindle://book?action=open&asin=B0BHCFNY9Q&location=512) ^ref-2713

---
dimensionality reduction, in which the goal is to simplify the data without losing too much information. — location: [526](kindle://book?action=open&asin=B0BHCFNY9Q&location=526) ^ref-53553

---
car’s mileage may be strongly correlated with its age, so the dimensionality reduction algorithm will merge them into one feature that represents the car’s wear and tear. This is called feature extraction. — location: [527](kindle://book?action=open&asin=B0BHCFNY9Q&location=527) ^ref-39856

---
It is often a good idea to try to reduce the number of dimensions in your training data using a dimensionality reduction algorithm before you feed it to another machine learning algorithm — location: [533](kindle://book?action=open&asin=B0BHCFNY9Q&location=533) ^ref-685

---
The system is shown mostly normal instances during training, so it learns to recognize them; then, when it sees a new instance, it can tell whether it looks like a normal one or whether it is likely an anomaly — location: [540](kindle://book?action=open&asin=B0BHCFNY9Q&location=540) ^ref-53643

---
if you have thousands of pictures of dogs, and 1% of these pictures represent Chihuahuas, then a novelty detection algorithm should not treat new pictures of Chihuahuas as novelties. On the other hand, anomaly detection algorithms may consider these dogs as so rare and so different from other dogs that they would likely classify them as anomalies (no offense to Chihuahuas). — location: [546](kindle://book?action=open&asin=B0BHCFNY9Q&location=546) ^ref-32234

---
another common unsupervised task is association rule learning, in which the goal is to dig into large amounts of data and discover interesting relations between attributes. For example, suppose you own a supermarket. Running an association rule on your sales logs may reveal that people who purchase barbecue sauce and potato chips also tend to buy steak. Thus, you may want to place these items close to one another. — location: [552](kindle://book?action=open&asin=B0BHCFNY9Q&location=552) ^ref-6136

---
Another approach to machine learning involves actually generating a fully labeled dataset from a fully unlabeled one. Again, once the whole dataset is labeled, any supervised learning algorithm can be used. This approach is called self-supervised learning. — location: [572](kindle://book?action=open&asin=B0BHCFNY9Q&location=572) ^ref-11783

---
suppose that what you really want is to have a pet classification model: given a picture of any pet, it will tell you what species it belongs to. If you have a large dataset of unlabeled photos of pets, you can start by training an image-repairing model using self-supervised learning. Once it’s performing well, it should be able to distinguish different pet species: when it repairs an image of a cat whose face is masked, it must know not to add a dog’s face. Assuming your model’s architecture allows it (and most neural network architectures do), it is then possible to tweak the model so that it predicts pet species instead of repairing images. The final step consists of fine-tuning the model on a labeled dataset: the model already knows what cats, dogs, and other pet species look like, so this step is only needed so the model can learn the mapping between the species it already knows and the labels we expect from it. — location: [582](kindle://book?action=open&asin=B0BHCFNY9Q&location=582) ^ref-36745

---
Transferring knowledge from one task to another is called transfer learning, — location: [591](kindle://book?action=open&asin=B0BHCFNY9Q&location=591) ^ref-26576

---
Reinforcement learning is a very different beast. The learning system, called an agent in this context, can observe the environment, select and perform actions, and get rewards in return (or penalties in the form of negative rewards, as shown in Figure 1-13). It must then learn by itself what is the best strategy, called a policy, to get the most reward over time. A policy defines what action the agent should choose when it is in a given situation. — location: [600](kindle://book?action=open&asin=B0BHCFNY9Q&location=600) ^ref-65262

---
In batch learning, the system is incapable of learning incrementally: it must be trained using all the available data. — location: [618](kindle://book?action=open&asin=B0BHCFNY9Q&location=618) ^ref-36948

---
First the system is trained, and then it is launched into production and runs without learning anymore; it just applies what it has learned. This is called offline learning. — location: [620](kindle://book?action=open&asin=B0BHCFNY9Q&location=620) ^ref-43250

---
Unfortunately, a model’s performance tends to decay slowly over time, simply because the world continues to evolve while the model remains unchanged. This phenomenon is often called model rot or data drift. — location: [622](kindle://book?action=open&asin=B0BHCFNY9Q&location=622) ^ref-50568

---
